{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Inference using Falcon 7B - Uncensored for generating toxic data"
      ],
      "metadata": {
        "id": "gvMVfZVTdiFq"
      },
      "id": "gvMVfZVTdiFq"
    },
    {
      "cell_type": "code",
      "id": "dLDmgUJKqf9LbcNgPiKRfbwg",
      "metadata": {
        "tags": [],
        "id": "dLDmgUJKqf9LbcNgPiKRfbwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1708989785358,
          "user_tz": 480,
          "elapsed": 6234,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "c8975116-95d7-47fe-a90c-0de5da6c7275"
      },
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!pip install transformers accelerate einops sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.27.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone the required repositories to be able to install AutoGPTQ"
      ],
      "metadata": {
        "id": "xf__M1ePeGIu"
      },
      "id": "xf__M1ePeGIu"
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf AutoGPTQ\n",
        "!git clone https://github.com/PanQiWei/AutoGPTQ.git && cd AutoGPTQ\n",
        "!git clone https://github.com/oobabooga/text-generation-webui"
      ],
      "metadata": {
        "id": "8PYFxQpMy9PZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1708989786754,
          "user_tz": 480,
          "elapsed": 1400,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "79a8d1ae-c77d-406f-f8b1-ae6c35fb817c"
      },
      "id": "8PYFxQpMy9PZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AutoGPTQ'...\n",
            "remote: Enumerating objects: 4688, done.\u001b[K\n",
            "remote: Counting objects: 100% (1430/1430), done.\u001b[K\n",
            "remote: Compressing objects: 100% (400/400), done.\u001b[K\n",
            "remote: Total 4688 (delta 1137), reused 1245 (delta 1028), pack-reused 3258\u001b[K\n",
            "Receiving objects: 100% (4688/4688), 8.13 MiB | 23.45 MiB/s, done.\n",
            "Resolving deltas: 100% (3043/3043), done.\n",
            "fatal: destination path 'text-generation-webui' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/"
      ],
      "metadata": {
        "id": "n0D7SavmzAKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1708989794409,
          "user_tz": 480,
          "elapsed": 6288,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "8ac28ac5-3883-4a36-8921-d2e12e070c72"
      },
      "id": "n0D7SavmzAKT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://huggingface.github.io/autogptq-index/whl/cu118/\n",
            "Requirement already satisfied: auto-gptq in /usr/local/lib/python3.10/dist-packages (0.8.0.dev0+cu1222)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.27.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (2.17.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.1.99)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.25.2)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.0.1)\n",
            "Requirement already satisfied: gekko in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.0.6)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (2.1.0+cu121)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.4.2)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (4.35.2)\n",
            "Requirement already satisfied: peft>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (4.66.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->auto-gptq) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->auto-gptq) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->auto-gptq) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->auto-gptq) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (0.15.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (15.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (3.9.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge->auto-gptq) (1.16.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->auto-gptq) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2023.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->auto-gptq) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE: Use the pip install code below if the inference speed slows down to download the latest version for AutoGPTQ"
      ],
      "metadata": {
        "id": "tGPDTuVy1jCG"
      },
      "id": "tGPDTuVy1jCG"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"git+https://github.com/PanQiWei/AutoGPTQ.git@v0.4.2\""
      ],
      "metadata": {
        "id": "GGwwm5Qa1hE1"
      },
      "id": "GGwwm5Qa1hE1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to install the version below if the inference speed slows down."
      ],
      "metadata": {
        "id": "PcVPa6rm1D1i"
      },
      "id": "PcVPa6rm1D1i"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q auto-gptq==0.4.2\n",
        "from auto_gptq import AutoGPTQForCausalLM"
      ],
      "metadata": {
        "id": "tJs-0ayo4gHV"
      },
      "id": "tJs-0ayo4gHV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install auto_gptq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNBqV1ck3Na3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1708940281185,
          "user_tz": 480,
          "elapsed": 6426,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "1df9d811-15d7-47c1-d734-6113d8134ab1"
      },
      "id": "yNBqV1ck3Na3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: auto_gptq in /usr/local/lib/python3.10/dist-packages (0.7.0+cu118)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (0.27.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (2.17.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (0.1.99)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (1.25.2)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (1.0.1)\n",
            "Requirement already satisfied: gekko in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (1.0.6)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (2.1.0+cu121)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (0.4.2)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (4.35.2)\n",
            "Requirement already satisfied: peft>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (0.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (4.66.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->auto_gptq) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->auto_gptq) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->auto_gptq) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->auto_gptq) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto_gptq) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto_gptq) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto_gptq) (0.15.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto_gptq) (15.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->auto_gptq) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto_gptq) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->auto_gptq) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->auto_gptq) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->auto_gptq) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->auto_gptq) (3.9.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge->auto_gptq) (1.16.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto_gptq) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto_gptq) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto_gptq) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto_gptq) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto_gptq) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto_gptq) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto_gptq) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto_gptq) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto_gptq) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto_gptq) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->auto_gptq) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto_gptq) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto_gptq) (2023.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->auto_gptq) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%reset"
      ],
      "metadata": {
        "id": "Cnv5OOMy3Sv_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1708942325449,
          "user_tz": 480,
          "elapsed": 2488,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "3000ee92-640e-40cb-dd7e-305939919f98"
      },
      "id": "Cnv5OOMy3Sv_",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load the model:"
      ],
      "metadata": {
        "id": "Gqp8Ttfv0h-4"
      },
      "id": "Gqp8Ttfv0h-4"
    },
    {
      "cell_type": "code",
      "source": [
        "# import the required libraries\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from auto_gptq import AutoGPTQForCausalLM"
      ],
      "metadata": {
        "id": "yWtftg6r1x6c"
      },
      "id": "yWtftg6r1x6c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"TheBloke/WizardLM-Uncensored-Falcon-7B-GPTQ\""
      ],
      "metadata": {
        "id": "7VX9I4mlzAk0"
      },
      "id": "7VX9I4mlzAk0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)"
      ],
      "metadata": {
        "id": "Ahp_DhhQzB-_",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1709322951028,
          "user_tz": 480,
          "elapsed": 1905,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "5514e5546f1d45ffaabb53c9c3fda3cb",
            "80a59e81d4864196bdfc33c2378ac470",
            "6ffd29b0172d42e3bf8e1efb7db30f65",
            "9cfd71f8e9f54bcdbc170080c1422397",
            "547be3947eef48be9c701d0b6233140d",
            "dc830b85e528414e9f69fb3a87be113e",
            "c1300df45b5a4fa2b42dfed36cd3a126",
            "ed1222a0828a441aa877a1b3315e33b7",
            "86192c35160d4c799a31e9fc4c6b4461",
            "f373d5420ac74168ba3069b7e1fbfd89",
            "e02a46e936884245b60a259128786b87",
            "6c3b91a306d24d0d9d57f7b7f1e3c41b",
            "2b802957ffb446d9bf2aec8036c3891c",
            "ed3d0820c4eb4b5ca90514d4d413d057",
            "18c8b7fe1fcc4362a56559f7aa06e863",
            "48b95f12a6fe4226ac0b344568adfb2b",
            "8124582b688a4a678cbfe70fab418869",
            "77aea844574f4a78b9eb15c800fdbcda",
            "771183536696424ba21e1138458acbee",
            "0ce876cabc59474981563286c7ec9589",
            "08d9db76cd3741ad9259dbee437c6c84",
            "fe2e1a94d41a49998cdf710275351665",
            "6677b061a52b489398d31ea3254e57ad",
            "80935f7ac69c414baacba6bbab199dba",
            "5922ce9eccaa41bcb4cbc3016f0bbf46",
            "b7480a30026646f5aef3f7e1a87534fd",
            "e3ebf9049ad846e78bfca0666c5c8293",
            "10866282c8894e4d88951f7035c60a2d",
            "29ba3eb91acd4ae2a9ecfcffe223038c",
            "a6185bed416040209b3aadbd88386e75",
            "ac82a960051549c6b91cbe32dfe5552d",
            "9e487a2dc5264fedb7305b08fcfa413e",
            "25fd112a86a347d797bec295fb626aa4"
          ]
        },
        "outputId": "75eedbbe-e24c-4762-9041-a8c57049bcd7"
      },
      "id": "Ahp_DhhQzB-_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/207 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5514e5546f1d45ffaabb53c9c3fda3cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.73M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c3b91a306d24d0d9d57f7b7f1e3c41b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/305 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6677b061a52b489398d31ea3254e57ad"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure that you are connected to a GPU:"
      ],
      "metadata": {
        "id": "K2tez5fc1SOY"
      },
      "id": "K2tez5fc1SOY"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Check if CUDA (GPU support) is available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"CUDA is not available. Using CPU instead.\")"
      ],
      "metadata": {
        "id": "bWCIy23hzEr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1709322959996,
          "user_tz": 480,
          "elapsed": 12,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "060ca45c-c467-4553-fcf3-e378808c6860"
      },
      "id": "bWCIy23hzEr7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU: NVIDIA L4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch_dtype = torch.float16 if device.type == 'cuda' else torch.float32 # change the datatype based on if the gpu type is cuda.\n",
        "\n",
        "model = AutoGPTQForCausalLM.from_quantized(model_path, device=\"cuda:0\", use_triton=False, torch_dtype = torch_dtype, use_safetensors=True, trust_remote_code=True, disable_exllamav2=True)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "HGDbsW2Aea05",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1709274575839,
          "user_tz": 480,
          "elapsed": 63073,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "9d29fb7d-7937-482d-8ada-ff0ad4300010",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "HGDbsW2Aea05",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - The layer lm_head is not quantized.\n",
            "INFO:auto_gptq.modeling._base:The layer lm_head is not quantized.\n",
            "WARNING - can't get model's sequence length from model config, will set to 4096.\n",
            "WARNING:auto_gptq.modeling._base:can't get model's sequence length from model config, will set to 4096.\n",
            "WARNING - RWGPTQForCausalLM hasn't fused attention module yet, will skip inject fused attention.\n",
            "WARNING:auto_gptq.modeling._base:RWGPTQForCausalLM hasn't fused attention module yet, will skip inject fused attention.\n",
            "WARNING - RWGPTQForCausalLM hasn't fused mlp module yet, will skip inject fused mlp.\n",
            "WARNING:auto_gptq.modeling._base:RWGPTQForCausalLM hasn't fused mlp module yet, will skip inject fused mlp.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RWGPTQForCausalLM(\n",
              "  (model): RWForCausalLM(\n",
              "    (transformer): RWModel(\n",
              "      (word_embeddings): Embedding(65025, 4544)\n",
              "      (h): ModuleList(\n",
              "        (0-31): 32 x DecoderLayer(\n",
              "          (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
              "          (self_attention): Attention(\n",
              "            (maybe_rotary): RotaryEmbedding()\n",
              "            (query_key_value): QuantLinear()\n",
              "            (dense): QuantLinear()\n",
              "            (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (mlp): MLP(\n",
              "            (dense_h_to_4h): QuantLinear()\n",
              "            (act): GELU(approximate='none')\n",
              "            (dense_4h_to_h): QuantLinear()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln_f): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (lm_head): Linear(in_features=4544, out_features=65025, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA (GPU support) is available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"CUDA is not available. Using CPU instead.\")"
      ],
      "metadata": {
        "id": "jnJ5ojkwzP1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1709274581824,
          "user_tz": 480,
          "elapsed": 255,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "c5fc6f4a-56d2-488b-863b-9f5ebfd85dbb"
      },
      "id": "jnJ5ojkwzP1-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU: NVIDIA L4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load your dataframe that consists of toxic examples:"
      ],
      "metadata": {
        "id": "0CNBxG9W-5IB"
      },
      "id": "0CNBxG9W-5IB"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/examples_for_prompt_cleaned.csv') # use your file path."
      ],
      "metadata": {
        "id": "1ZkDR3h0bswv"
      },
      "id": "1ZkDR3h0bswv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-h-nJOi8BsPx"
      },
      "id": "-h-nJOi8BsPx"
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompts to try:\n",
        "\n",
        "text_prompt = (\n",
        "      \"DEFINITION:\" f\"{DEFINITION}\\n\\n\"\n",
        "    \"Generate 5 offensive social media comments that conforms with the DEFINITION stated above. THE GENERATED COMMENTS SHOULD BE WRITTEN IN PLAIN ENGLISH AND GENERATE EACH COMMENT INSIDE DOUBLE QUOTES. :Below are a few examples of the kind of offensive comments that you need to generate:\\n\"\n",
        "    \"example1: \\\"What a fucking asshole bully. He deserves a long sentence! In reading the article, it's doubtful any friends and family will miss him.\\\"\\n\"\n",
        "      \"example2: \\\"Nsw are such shit they even wrecked a whole other country. Feel so sorry for the nzers\\\"\\n\"\n",
        "      )\n",
        "\n",
        "text_prompt = (\n",
        "      \"DEFINITION:\" f\"{DEFINITION}\\n\\n\"\n",
        "    \"Generate 5 offensive social media comments that conforms with the DEFINITION stated above. THE GENERATED COMMENTS SHOULD BE WRITTEN IN PLAIN ENGLISH AND GENERATE EACH COMMENT INSIDE DOUBLE QUOTES. :Below are a few examples of the kind of offensive comments that you need to generate:\\n\"\n",
        "    \"example1: \\\"These scuzzballs will just get on GoFundMe and claim that evil Biden and the Deep State are illegally using the courts to bully them into silence, but they need YOUR HELP to keep exposing DEM CORRUPTION.\\\"\\n\"\n",
        "      \"example2: \\\"As an Arkansan, fuck Asa. What a piece of shit. I've lost two coworkers at the hospital I work at to COVID. Fuck him, and fuck the GOP, and fuck all the ignorant ass hillbilly rejects that perpetuate the misinformation. They're getting people killed.\\\"\\n\"\n",
        "      )\n",
        "\n",
        "text_prompt = (\n",
        "      \"DEFINITION:\" f\"{DEFINITION}\\n\\n\"\n",
        "    \"Generate 5 offensive social media comments that conforms with the DEFINITION stated above. THE GENERATED COMMENTS SHOULD BE WRITTEN IN PLAIN ENGLISH AND GENERATE EACH COMMENT INSIDE DOUBLE QUOTES. :Below are a few examples of the kind of offensive comments that you need to generate:\\n\"\n",
        "    \"example1: \\\"I dunno. They do an awful lot of raping for people who don't objectify women\\\"\\n\"\n",
        "      \"example2: \\\"What the hell does the number of patients in hospital have to do with this storm coming? Anything to boost your narrative I guess...shameless media whores you are.\\\"\\n\"\n",
        "  )\n",
        "\n",
        "text_prompt = (\n",
        "      \"Below are a few examples of the kind of offensive comments that you need to generate:\\n\"\n",
        "      \"example1: \\\"What a fucking asshole bully. He deserves a long sentence! In reading the article, it's doubtful any friends and family will miss him.\\\"\\n\"\n",
        "      \"example2: \\\"what do you expect when the rulers of their country are the same rulers who televised beheadings, slaughtered innocent people and were sexist towards women, you make me want to projectile vomit straight in your face 🤢🤮 I feel bad about the fact that you think you’re so clever\\\"\\n\"\n",
        "      \"example3: \\\"Yep, meanwhile Trump is still trying to point out Afghanistan on the map. Illiterate orange clown and his cult. Hilarious you attack biden when bonespurs can't even read at a 3rd grade level.\\\"\\n\"\n",
        "      \"DEFINITION:\" f\"{DEFINITION}\\n\\n\"\n",
        "      \"Generate 5 new offensive social media (Facebook) comments that conforms with the DEFINITION stated above. THE GENERATED COMMENTS SHOULD BE WRITTEN IN PLAIN ENGLISH AND GENERATE EACH OF THE 5 COMMENTS INSIDE DOUBLE QUOTES AND OF LENGTH IN BETWEEN 20 AND 100 WORDS AND VARY THE LENGTH FOR THE COMMENTS. (NOTE: MAKE SURE TO NOT GENERATE THE SAME COMMENTS AS THE EXAMPLES SHOWN ABOVE)\"\n",
        "  )\n",
        "\n",
        "text_prompt = (\n",
        "        \"DEFINITION:\" f\"{DEFINITION}\\n\\n\"\n",
        "        \"Generate 5 offensive social media comments maybe a couple comments on real world politics that conforms with the DEFINITION stated above and include a couple witty ones that would direclty not seem like offensive but is offensive. THE GENERATED COMMENTS SHOULD BE WRITTEN IN PLAIN ENGLISH AND GENERATE THE COMMENT INSIDE DOUBLE QUOTES\"\n",
        "        )\n",
        "\n",
        "text_prompt = (\n",
        "        \"DEFINITION:\" f\"{DEFINITION}\\n\\n\"\n",
        "        \"Generate a social media comment which is both hateful and offensive and that conforms with the DEFINITION stated above. THE GENERATED COMMENT SHOULD BE WRITTEN IN PLAIN ENGLISH AND GENERATE THE COMMENT INSIDE DOUBLE QUOTES\"\n",
        "        )\n",
        "\n",
        "text_prompt = (\n",
        "    f\"DEFINITION: {DEFINITION}\\n\\n\"\n",
        "    f\"Generate 5 social media comments which are both offensive and that conforms with the DEFINITION stated above. THE GENERATED COMMENTS SHOULD BE WRITTEN IN PLAIN ENGLISH AND GENERATE EACH OF THE 5 COMMENTS INSIDE DOUBLE QUOTES AND OF LENGTH IN BETWEEN 20 AND 100 WORDS AND VARY THE LENGTH FOR THE COMMENTS\"\n",
        "  )\n",
        "\n",
        "text_prompt = (\n",
        "      \"DEFINITION:\" f\"{DEFINITION}\\n\\n\"\n",
        "    \"Generate 5 offensive social media comments that conforms with the DEFINITION stated above. THE GENERATED COMMENTS SHOULD BE WRITTEN IN PLAIN ENGLISH AND GENERATE EACH COMMENT INSIDE DOUBLE QUOTES. :Below are a few examples of the kind of offensive comments that you need to generate:\\n\"\n",
        "    \"example1: \\\"What a fucking asshole bully. He deserves a long sentence! In reading the article, it's doubtful any friends and family will miss him.\\\"\\n\"\n",
        "      \"example2: \\\"Nsw are such shit they even wrecked a whole other country. Feel so sorry for the nzers\\\"\\n\"\n",
        "      )\n",
        "\n",
        "text_prompt = (\n",
        "      \"DEFINITION:\" f\"{DEFINITION}\\n\\n\"\n",
        "    \"Generate 5 offensive social media (Facebook) comments that conforms with the DEFINITION stated above. THE GENERATED COMMENTS SHOULD BE WRITTEN IN PLAIN ENGLISH AND GENERATE EACH COMMENT INSIDE DOUBLE QUOTES GENERATE EACH OF THE 5 COMMENTS INSIDE DOUBLE QUOTES AND OF LENGTH IN BETWEEN 20 AND 100 WORDS AND VARY THE LENGTH FOR THE COMMENT.\n",
        "      )"
      ],
      "metadata": {
        "id": "HxEiXIlKBs41"
      },
      "id": "HxEiXIlKBs41",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to generate the data based on prompting for a given category from the category list"
      ],
      "metadata": {
        "id": "q8F_opKl2jgQ"
      },
      "id": "q8F_opKl2jgQ"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "import torch\n",
        "\n",
        "def generate_category_data(CATEGORY, model = model):\n",
        "  model = model.to(device)\n",
        "  generated_examples = []\n",
        "  generated_hashtags = []\n",
        "  start_time = time.time()\n",
        "\n",
        "  n_examples = 1 # for each of the two examples that you provide in the prompt generate n_examples times using the same prompt.\n",
        "\n",
        "  DEFINITION = \"\"\" OFFENSIVE COMMENTS: contains hurtful, derogatory, or obscene comments \"\"\"\n",
        "\n",
        "  # Create the text prompt\n",
        "  text_prompt = (\n",
        "      \"DEFINITION:\" f\"{DEFINITION}\\n\\n\"\n",
        "    \"Generate 5 offensive social media comments that conforms with the DEFINITION stated above targeting \" f\"{CATEGORY}. THE GENERATED COMMENTS SHOULD BE WRITTEN IN PLAIN ENGLISH AND GENERATE EACH COMMENT INSIDE DOUBLE QUOTES. :Below are a few examples of the kind of offensive comments that you need to generate:\\n\"\n",
        "    \"example1: \\\"What a fucking asshole bully. He deserves a long sentence! In reading the article, it's doubtful any friends and family will miss him.\\\"\\n\"\n",
        "      \"example2: \\\"Nsw are such shit they even wrecked a whole other country. Feel so sorry for the nzers\\\"\\n\"\n",
        "      )\n",
        "\n",
        "  prompt = text_prompt\n",
        "  prompt_template = f\"### Instruction: {prompt}\\n### Response:\"\n",
        "  tokens = tokenizer(prompt_template, return_tensors=\"pt\").input_ids.to(device)\n",
        "\n",
        "  encoding = tokenizer(prompt_template, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "  input_ids = encoding.input_ids.to(device)\n",
        "  attention_mask = encoding.attention_mask.to(device)\n",
        "\n",
        "  for i in range(n_examples):\n",
        "    output = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,  # Pass the attention mask here\n",
        "        pad_token_id=tokenizer.eos_token_id,  # Set pad_token_id here\n",
        "        max_new_tokens=256,\n",
        "        do_sample=True,\n",
        "        temperature=0.8\n",
        "    )\n",
        "\n",
        "    txt=tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    #print(txt)\n",
        "\n",
        "    response_pattern = r\"### Response:(.*?)(?=### |$)\"\n",
        "\n",
        "    response_match = re.search(response_pattern, txt, re.DOTALL)\n",
        "    # print(response_match)\n",
        "\n",
        "    if response_match:\n",
        "        response_text = response_match.group(1)\n",
        "        cleaned_text=response_text.strip() # Use strip() to remove leading/trailing whitespace\n",
        "            # Remove hashtags and the words attached to them\n",
        "        cleaned_text = re.sub(r'#\\w+', '', cleaned_text)\n",
        "    else:\n",
        "        cleaned_text=None\n",
        "\n",
        "    quoted_text = cleaned_text\n",
        "    #print(\"QUOTED TEXT: \", quoted_text)\n",
        "\n",
        "    if quoted_text == None or quoted_text == \"\":\n",
        "      quoted_text = \"\"\n",
        "\n",
        "  ####\n",
        "\n",
        "    hashtags = re.findall(r\"#(\\w+)\", txt)\n",
        "    hashtags_str = ', #'.join(hashtags)\n",
        "    generated_examples.extend(re.findall(r'\"([^\"]*)\"', quoted_text))\n",
        "    generated_hashtags.append(hashtags_str)\n",
        "    print(\"Generated output: \", i)\n",
        "\n",
        "  end_time = time.time()\n",
        "  print(\"Finished category: \", CATEGORY)\n",
        "\n",
        "  print(\"Total time taken: \", end_time - start_time)\n",
        "\n",
        "  return generated_examples"
      ],
      "metadata": {
        "id": "6rhVo5J1zTSI"
      },
      "id": "6rhVo5J1zTSI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to generate data by prompting with examples:"
      ],
      "metadata": {
        "id": "DeLhgFiH2tZZ"
      },
      "id": "DeLhgFiH2tZZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# the function returns a list of toxic generated examples, (i.e each example is a string)\n",
        "# df will be the dataframe that you will be passing that consists of toxic examples, the prompt takes in 2 rows each time and prompts\n",
        "# the model to generate 5 examples.\n",
        "\n",
        "def generate_data(df, model = model):\n",
        "    model = model.to(device)\n",
        "    generated_examples = []\n",
        "    generated_hashtags = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    DEFINITION = \"\"\" OFFENSIVE COMMENTS: contains hurtful, derogatory, or obscene comments \"\"\"\n",
        "\n",
        "    for i in range(0, len(df), 2):\n",
        "        example1 = df.iloc[i]['example']\n",
        "        example2 = df.iloc[i + 1]['example'] if i + 1 < len(df) else ''\n",
        "\n",
        "        n_examples = 5 # for each of the two examples that you provide in the prompt generate n_examples times using the same prompt.\n",
        "\n",
        "        # the prompt below asks to generate 5 posts within double quotes, so that we can extract it in a much easier way using regex.\n",
        "        # you can change your prompts and try different prompt engineering techniques.\n",
        "        text_prompt = (\n",
        "            \"DEFINITION:\" f\"{DEFINITION}\\n\\n\"\n",
        "            \"Generate 5 offensive social media comments that conforms with the DEFINITION stated above. \"\n",
        "            \"THE GENERATED COMMENTS SHOULD BE WRITTEN IN PLAIN ENGLISH AND GENERATE EACH COMMENT INSIDE DOUBLE QUOTES \"\n",
        "            \"GENERATE EACH OF THE 5 COMMENTS INSIDE DOUBLE QUOTES AND OF LENGTH IN BETWEEN 20 AND 100 WORDS AND VARY THE LENGTH FOR THE COMMENT. \"\n",
        "            \"Below are a few examples of the kind of offensive comments that you need to generate:\\n\"\n",
        "            f\"example1: \\\"{example1}\\\"\\n\"\n",
        "            f\"example2: \\\"{example2}\\\"\\n\"\n",
        "        )\n",
        "\n",
        "        prompt = text_prompt\n",
        "        prompt_template = f\"### Instruction: {prompt}\\n### Response:\"\n",
        "        tokens = tokenizer(prompt_template, return_tensors=\"pt\").input_ids.to(device)\n",
        "\n",
        "        encoding = tokenizer(prompt_template, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "        input_ids = encoding.input_ids.to(device)\n",
        "        attention_mask = encoding.attention_mask.to(device)\n",
        "\n",
        "\n",
        "        for j in range(n_examples):\n",
        "          output = model.generate(\n",
        "              input_ids=input_ids,\n",
        "              attention_mask=attention_mask,\n",
        "              pad_token_id=tokenizer.eos_token_id,\n",
        "              max_new_tokens=256,\n",
        "              do_sample=True,\n",
        "              temperature=0.8\n",
        "          )\n",
        "\n",
        "          txt=tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "          response_pattern = r\"### Response:(.*?)(?=### |$)\"\n",
        "          response_match = re.search(response_pattern, txt, re.DOTALL)\n",
        "\n",
        "          if response_match:\n",
        "              response_text = response_match.group(1)\n",
        "              cleaned_text=response_text.strip() # Use strip() to remove leading/trailing whitespace\n",
        "                  # Remove hashtags and the words attached to them\n",
        "              cleaned_text = re.sub(r'#\\w+', '', cleaned_text)\n",
        "          else:\n",
        "              cleaned_text=None\n",
        "\n",
        "          quoted_text = cleaned_text\n",
        "          #print(\"QUOTED TEXT: \", quoted_text)\n",
        "\n",
        "          if quoted_text == None or quoted_text == \"\":\n",
        "            quoted_text = \"\"\n",
        "\n",
        "          hashtags = re.findall(r\"#(\\w+)\", txt)\n",
        "          hashtags_str = ', #'.join(hashtags)\n",
        "          generated_examples.extend(re.findall(r'\"([^\"]*)\"', quoted_text)) # extracting text within double quotes\n",
        "          generated_hashtags.append(hashtags_str)\n",
        "          #print(\"Generated output: \", j)\n",
        "\n",
        "        end_time = time.time()\n",
        "        print(\"Finished set: \", i) # printing the number of the set finished, it will all be even numbers since we are using 2 examples at the same time.\n",
        "\n",
        "        print(\"Total time taken: \", end_time - start_time) # time taken for inference for each set.\n",
        "\n",
        "    return generated_examples"
      ],
      "metadata": {
        "id": "uyLhlDEteDGL"
      },
      "id": "uyLhlDEteDGL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# store the generated data in a list.\n",
        "\n",
        "data_offensive = generate_data(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzeo5rdEfz-H",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1709323688682,
          "user_tz": 480,
          "elapsed": 614672,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "62c27e7a-7517-44bd-d205-dcb6b6d0cf99"
      },
      "id": "mzeo5rdEfz-H",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished set:  0\n",
            "Total time taken:  318.9509971141815\n",
            "Finished set:  2\n",
            "Total time taken:  614.3444910049438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add the data to a dataframe:"
      ],
      "metadata": {
        "id": "Qyz3noQx3u1H"
      },
      "id": "Qyz3noQx3u1H"
    },
    {
      "cell_type": "code",
      "source": [
        "data_examples_offensive = pd.DataFrame({\n",
        "    'text': data_offensive,\n",
        "    'hateful': 0,\n",
        "    'offensive': 1,\n",
        "    'toxic': 0,\n",
        "    'toxicity': 1\n",
        "}) # change the values to be 0 or 1 based on if you are trying to generate offensive, hateful or toxic text."
      ],
      "metadata": {
        "id": "-VGZ0K2-iHKS"
      },
      "id": "-VGZ0K2-iHKS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the data as a csv file:"
      ],
      "metadata": {
        "id": "N3jhsaew3y2R"
      },
      "id": "N3jhsaew3y2R"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "data_examples_offensive_4.to_csv('your_filename.csv', index=False)\n",
        "\n",
        "files.download('your_filename.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "6rB43Sb4iVjd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1709323689440,
          "user_tz": 480,
          "elapsed": 10,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "21d85ed8-e74a-48f0-f778-5e8719e474e5"
      },
      "id": "6rB43Sb4iVjd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bbb075d1-8e37-4acb-9939-6688597ea25e\", \"RRAVIPRA_OFFENSIVE_PROMPT_EXAMPLES_5_40b.csv\", 67515)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating data targeting a specific category:"
      ],
      "metadata": {
        "id": "w-gq_vvC_uzi"
      },
      "id": "w-gq_vvC_uzi"
    },
    {
      "cell_type": "code",
      "source": [
        "categories_list = [\n",
        "    \"Muslims\",\n",
        "    \"Jews\",\n",
        "    \"Sikhs\",\n",
        "    \"Buddhists\",\n",
        "    \"Transgender individuals\",\n",
        "    \"Non-binary individuals\",\n",
        "    \"Women\",\n",
        "    \"LGBTQ+ individuals\",\n",
        "    \"Persons with disabilities\",\n",
        "    \"Refugees\",\n",
        "    \"Indigenous Peoples\",\n",
        "    \"Black/African American\",\n",
        "    \"Latinx\",\n",
        "    \"Asian Americans/Pacific Islanders\"\n",
        "]"
      ],
      "metadata": {
        "id": "pivgzY4ABM5h"
      },
      "id": "pivgzY4ABM5h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_generation = []\n",
        "\n",
        "for CATEGORY in categories_list:\n",
        "  final_generation.extend(generate_category_data(CATEGORY))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcVuzNCWyMSB",
        "outputId": "1db24bb5-6590-407f-98c1-8da629bcd1ce",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1708621793929,
          "user_tz": 480,
          "elapsed": 17512333,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "hcVuzNCWyMSB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated output:  0\n",
            "Generated output:  1\n",
            "Generated output:  2\n",
            "Generated output:  3\n",
            "Generated output:  4\n",
            "Generated output:  5\n",
            "Generated output:  6\n",
            "Generated output:  7\n",
            "Generated output:  8\n",
            "Generated output:  9\n",
            "Generated output:  10\n",
            "Generated output:  11\n",
            "Generated output:  12\n",
            "Generated output:  13\n",
            "Generated output:  14\n",
            "Finished category:  Muslims\n",
            "Total time taken:  2400.393069267273\n",
            "Generated output:  0\n",
            "Generated output:  1\n",
            "Generated output:  2\n",
            "Generated output:  3\n",
            "Generated output:  4\n",
            "Generated output:  5\n",
            "Generated output:  6\n",
            "Generated output:  7\n",
            "Generated output:  8\n",
            "Generated output:  9\n",
            "Generated output:  10\n",
            "Generated output:  11\n",
            "Generated output:  12\n",
            "Generated output:  13\n",
            "Generated output:  14\n",
            "Finished category:  Jews\n",
            "Total time taken:  2401.563175678253\n",
            "Generated output:  0\n",
            "Generated output:  1\n",
            "Generated output:  2\n",
            "Generated output:  3\n",
            "Generated output:  4\n",
            "Generated output:  5\n",
            "Generated output:  6\n",
            "Generated output:  7\n",
            "Generated output:  8\n",
            "Generated output:  9\n",
            "Generated output:  10\n",
            "Generated output:  11\n",
            "Generated output:  12\n",
            "Generated output:  13\n",
            "Generated output:  14\n",
            "Finished category:  Sikhs\n",
            "Total time taken:  2403.1604719161987\n",
            "Generated output:  0\n",
            "Generated output:  1\n",
            "Generated output:  2\n",
            "Generated output:  3\n",
            "Generated output:  4\n",
            "Generated output:  5\n",
            "Generated output:  6\n",
            "Generated output:  7\n",
            "Generated output:  8\n",
            "Generated output:  9\n",
            "Generated output:  10\n",
            "Generated output:  11\n",
            "Generated output:  12\n",
            "Generated output:  13\n",
            "Generated output:  14\n",
            "Finished category:  Buddhists\n",
            "Total time taken:  2403.6364557743073\n",
            "Generated output:  0\n",
            "Generated output:  1\n",
            "Generated output:  2\n",
            "Generated output:  3\n",
            "Generated output:  4\n",
            "Generated output:  5\n",
            "Generated output:  6\n",
            "Generated output:  7\n",
            "Generated output:  8\n",
            "Generated output:  9\n",
            "Generated output:  10\n",
            "Generated output:  11\n",
            "Generated output:  12\n",
            "Generated output:  13\n",
            "Generated output:  14\n",
            "Finished category:  Transgender individuals\n",
            "Total time taken:  2405.0058131217957\n",
            "Generated output:  0\n",
            "Generated output:  1\n",
            "Generated output:  2\n",
            "Generated output:  3\n",
            "Generated output:  4\n",
            "Generated output:  5\n",
            "Generated output:  6\n",
            "Generated output:  7\n",
            "Generated output:  8\n",
            "Generated output:  9\n",
            "Generated output:  10\n",
            "Generated output:  11\n",
            "Generated output:  12\n",
            "Generated output:  13\n",
            "Generated output:  14\n",
            "Finished category:  Non-binary individuals\n",
            "Total time taken:  2406.488658428192\n",
            "Generated output:  0\n",
            "Generated output:  1\n",
            "Generated output:  2\n",
            "Generated output:  3\n",
            "Generated output:  4\n",
            "Generated output:  5\n",
            "Generated output:  6\n",
            "Generated output:  7\n",
            "Generated output:  8\n",
            "Generated output:  9\n",
            "Generated output:  10\n",
            "Generated output:  11\n",
            "Generated output:  12\n",
            "Generated output:  13\n",
            "Generated output:  14\n",
            "Finished category:  Women\n",
            "Total time taken:  2403.450564622879\n",
            "Generated output:  0\n",
            "Generated output:  1\n",
            "Generated output:  2\n",
            "Generated output:  3\n",
            "Generated output:  4\n",
            "Generated output:  5\n",
            "Generated output:  6\n",
            "Generated output:  7\n",
            "Generated output:  8\n",
            "Generated output:  9\n",
            "Generated output:  10\n",
            "Generated output:  11\n",
            "Generated output:  12\n",
            "Generated output:  13\n",
            "Generated output:  14\n",
            "Finished category:  LGBTQ+ individuals\n",
            "Total time taken:  2405.1242113113403\n",
            "Generated output:  0\n",
            "Generated output:  1\n",
            "Generated output:  2\n",
            "Generated output:  3\n",
            "Generated output:  4\n",
            "Generated output:  5\n",
            "Generated output:  6\n",
            "Generated output:  7\n",
            "Generated output:  8\n",
            "Generated output:  9\n",
            "Generated output:  10\n",
            "Generated output:  11\n",
            "Generated output:  12\n",
            "Generated output:  13\n",
            "Generated output:  14\n",
            "Finished category:  Persons with disabilities\n",
            "Total time taken:  2403.005856990814\n",
            "Generated output:  0\n",
            "Generated output:  1\n",
            "Generated output:  2\n",
            "Generated output:  3\n",
            "Generated output:  4\n",
            "Generated output:  5\n",
            "Generated output:  6\n",
            "Generated output:  7\n",
            "Generated output:  8\n",
            "Generated output:  9\n",
            "Generated output:  10\n",
            "Generated output:  11\n",
            "Generated output:  12\n",
            "Generated output:  13\n",
            "Generated output:  14\n",
            "Finished category:  Refugees\n",
            "Total time taken:  2402.0920929908752\n",
            "Generated output:  0\n",
            "Generated output:  1\n",
            "Generated output:  2\n",
            "Generated output:  3\n",
            "Generated output:  4\n",
            "Generated output:  5\n",
            "Generated output:  6\n",
            "Generated output:  7\n",
            "Generated output:  8\n",
            "Generated output:  9\n",
            "Generated output:  10\n",
            "Generated output:  11\n",
            "Generated output:  12\n",
            "Generated output:  13\n",
            "Generated output:  14\n",
            "Finished category:  Indigenous Peoples\n",
            "Total time taken:  2402.866635799408\n",
            "Generated output:  0\n",
            "Generated output:  1\n",
            "Generated output:  2\n",
            "Generated output:  3\n",
            "Generated output:  4\n",
            "Generated output:  5\n",
            "Generated output:  6\n",
            "Generated output:  7\n",
            "Generated output:  8\n",
            "Generated output:  9\n",
            "Generated output:  10\n",
            "Generated output:  11\n",
            "Generated output:  12\n",
            "Generated output:  13\n",
            "Generated output:  14\n",
            "Finished category:  Black/African American\n",
            "Total time taken:  2405.3226068019867\n",
            "Generated output:  0\n",
            "Generated output:  1\n",
            "Generated output:  2\n",
            "Generated output:  3\n",
            "Generated output:  4\n",
            "Generated output:  5\n",
            "Generated output:  6\n",
            "Generated output:  7\n",
            "Generated output:  8\n",
            "Generated output:  9\n",
            "Generated output:  10\n",
            "Generated output:  11\n",
            "Generated output:  12\n",
            "Generated output:  13\n",
            "Generated output:  14\n",
            "Finished category:  Latinx\n",
            "Total time taken:  2404.4511499404907\n",
            "Generated output:  0\n",
            "Generated output:  1\n",
            "Generated output:  2\n",
            "Generated output:  3\n",
            "Generated output:  4\n",
            "Generated output:  5\n",
            "Generated output:  6\n",
            "Generated output:  7\n",
            "Generated output:  8\n",
            "Generated output:  9\n",
            "Generated output:  10\n",
            "Generated output:  11\n",
            "Generated output:  12\n",
            "Generated output:  13\n",
            "Generated output:  14\n",
            "Finished category:  Asian Americans/Pacific Islanders\n",
            "Total time taken:  2408.6175243854523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_final_generation = pd.DataFrame({\n",
        "    'text': final_generation,\n",
        "    'hateful': 0,\n",
        "    'offensive': 1,\n",
        "    'toxic': 0,\n",
        "    'toxicity': 1\n",
        "}) # change the values to be 0 or 1 based on if you are trying to generate offensive, hateful or toxic text."
      ],
      "metadata": {
        "id": "wxFlotmvBXZx"
      },
      "id": "wxFlotmvBXZx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can further do the same thing as before and download it as a csv file."
      ],
      "metadata": {
        "id": "4ccBRcScBSaY"
      },
      "id": "4ccBRcScBSaY"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5514e5546f1d45ffaabb53c9c3fda3cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80a59e81d4864196bdfc33c2378ac470",
              "IPY_MODEL_6ffd29b0172d42e3bf8e1efb7db30f65",
              "IPY_MODEL_9cfd71f8e9f54bcdbc170080c1422397"
            ],
            "layout": "IPY_MODEL_547be3947eef48be9c701d0b6233140d"
          }
        },
        "80a59e81d4864196bdfc33c2378ac470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc830b85e528414e9f69fb3a87be113e",
            "placeholder": "​",
            "style": "IPY_MODEL_c1300df45b5a4fa2b42dfed36cd3a126",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "6ffd29b0172d42e3bf8e1efb7db30f65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed1222a0828a441aa877a1b3315e33b7",
            "max": 207,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86192c35160d4c799a31e9fc4c6b4461",
            "value": 207
          }
        },
        "9cfd71f8e9f54bcdbc170080c1422397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f373d5420ac74168ba3069b7e1fbfd89",
            "placeholder": "​",
            "style": "IPY_MODEL_e02a46e936884245b60a259128786b87",
            "value": " 207/207 [00:00&lt;00:00, 16.9kB/s]"
          }
        },
        "547be3947eef48be9c701d0b6233140d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc830b85e528414e9f69fb3a87be113e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1300df45b5a4fa2b42dfed36cd3a126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed1222a0828a441aa877a1b3315e33b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86192c35160d4c799a31e9fc4c6b4461": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f373d5420ac74168ba3069b7e1fbfd89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e02a46e936884245b60a259128786b87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c3b91a306d24d0d9d57f7b7f1e3c41b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b802957ffb446d9bf2aec8036c3891c",
              "IPY_MODEL_ed3d0820c4eb4b5ca90514d4d413d057",
              "IPY_MODEL_18c8b7fe1fcc4362a56559f7aa06e863"
            ],
            "layout": "IPY_MODEL_48b95f12a6fe4226ac0b344568adfb2b"
          }
        },
        "2b802957ffb446d9bf2aec8036c3891c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8124582b688a4a678cbfe70fab418869",
            "placeholder": "​",
            "style": "IPY_MODEL_77aea844574f4a78b9eb15c800fdbcda",
            "value": "tokenizer.json: 100%"
          }
        },
        "ed3d0820c4eb4b5ca90514d4d413d057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_771183536696424ba21e1138458acbee",
            "max": 2734597,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ce876cabc59474981563286c7ec9589",
            "value": 2734597
          }
        },
        "18c8b7fe1fcc4362a56559f7aa06e863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08d9db76cd3741ad9259dbee437c6c84",
            "placeholder": "​",
            "style": "IPY_MODEL_fe2e1a94d41a49998cdf710275351665",
            "value": " 2.73M/2.73M [00:00&lt;00:00, 19.9MB/s]"
          }
        },
        "48b95f12a6fe4226ac0b344568adfb2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8124582b688a4a678cbfe70fab418869": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77aea844574f4a78b9eb15c800fdbcda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "771183536696424ba21e1138458acbee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ce876cabc59474981563286c7ec9589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08d9db76cd3741ad9259dbee437c6c84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe2e1a94d41a49998cdf710275351665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6677b061a52b489398d31ea3254e57ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80935f7ac69c414baacba6bbab199dba",
              "IPY_MODEL_5922ce9eccaa41bcb4cbc3016f0bbf46",
              "IPY_MODEL_b7480a30026646f5aef3f7e1a87534fd"
            ],
            "layout": "IPY_MODEL_e3ebf9049ad846e78bfca0666c5c8293"
          }
        },
        "80935f7ac69c414baacba6bbab199dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10866282c8894e4d88951f7035c60a2d",
            "placeholder": "​",
            "style": "IPY_MODEL_29ba3eb91acd4ae2a9ecfcffe223038c",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "5922ce9eccaa41bcb4cbc3016f0bbf46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6185bed416040209b3aadbd88386e75",
            "max": 305,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac82a960051549c6b91cbe32dfe5552d",
            "value": 305
          }
        },
        "b7480a30026646f5aef3f7e1a87534fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e487a2dc5264fedb7305b08fcfa413e",
            "placeholder": "​",
            "style": "IPY_MODEL_25fd112a86a347d797bec295fb626aa4",
            "value": " 305/305 [00:00&lt;00:00, 27.5kB/s]"
          }
        },
        "e3ebf9049ad846e78bfca0666c5c8293": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10866282c8894e4d88951f7035c60a2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29ba3eb91acd4ae2a9ecfcffe223038c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6185bed416040209b3aadbd88386e75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac82a960051549c6b91cbe32dfe5552d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e487a2dc5264fedb7305b08fcfa413e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25fd112a86a347d797bec295fb626aa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}